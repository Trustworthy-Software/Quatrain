Bears-1$$Wrong constructor picked up when deserializing object$$I discovered an issue with Jackson 2.7.8 (and Jackson 2.8.4) when several constructors have parameters annotated with  @JsonProperty but only one is annotated with @JsonCreator . Here's a test case to reproduce it:   This test throws an the following exception:   After some debugging, it looks like that  BasicDeserializerFactory#_addDeserializerConstructors(...) is looping over all the constructors, and is not favoring an explicit constructor over a non-explicit one. I actually don't know what should be the expected behavior: should jackson fail when two constructors are annotated, or should jackson favor the one annotated with  @JsonCreator . Both options look reasonable to me (and I'm actually removing one of the constructors).
Bears-2$$Missing  KeyDeserializer for CharSequence$$Looks like use of nominal Map key type of  CharSequence does not work yet (as of 2.7.8 / 2.8.6). This is something that is needed to work with certain frameworks, such as Avro's generated POJOs.
Bears-3$$ACCEPT_CASE_INSENSITIVE_PROPERTIES fails with @JsonUnwrapped$$(note: moved from  FasterXML/jackson-dataformat-csv#133 ) When trying to deserialize type like:   with case-insensitive mapper (  mapper.enable(MapperFeature.ACCEPT_CASE_INSENSITIVE_PROPERTIES); ) I get exception:
Bears-4$$ArrayIndexOutOfBoundsException on impossible non-static inner class constructor$$Minimal repro:     Fails like this:   Validation is missing for this impossible constructor. Works as expected when  InnerSomething is static.
Bears-5$$No Object Id found for an instance when using @ConstructorProperties$$Hi! We recently migrated from 2.4.6. to 2.8.1. and we encountered the issue. We use lombok's  @AllArgsConstructor which adds @ConstructorProperties to constructor. We also used @JsonIdentityInfo on our POJO which lead to JsonMappingException: No Object Id found for an instance exception. The following test code demonstrates the issue   Stack trace   Prior to the version 2.5.0 this was not an issue, because the offending method (  com.fasterxml.jackson.databind.deser.impl.PropertyValueBuffer.handleIdValue(DeserializationContext, Object) ) had a comment // TODO: is this an error case? and did nothing else.
Bears-6$$@JsonProperty(access = Access.READ_ONLY) - unexpected behaviour$$Hey,  I was hoping to make use of @JsonProperty(access = Access.READ_ONLY), but failed.  Assume this class:   I couldn't find a way to stop the deserializer from attempting to deserialize the field "fullName".  The only thing that helps is to create a setter and annotate it with @JsonIgnore . However, that setter does not make sense and I don't want to have it. Is this a bug in behaviour or am I missing something? Thanks
Bears-7$$@JsonEnumDefaultValue should take precedence over FAIL_ON_NUMBERS_FOR_ENUMS$$Consider the following  ObjectMapper definition:  With this  ObjectMapper , when one attempts to deserialize an enum value V for an enum with an @JsonEnumDefaultValue element, the deserialization will:   Pass, if  Pass, if  Fail, if  To me this seems highly unintuitive. I would have expected the  READ_UNKNOWN_ENUM_VALUES_USING_DEFAULT_VALUE feature to take precedence over the FAIL_ON_NUMBERS_FOR_ENUMS feature in those cases where it applies (i.e., when deserializing an enum with a default element). I've put together a test class enumerating the relevant cases. See the inline comments towards the bottom. In four cases I feel that Jackson's current behavior is not as one might expect.   Would love to hear your thoughts on this. (If there is some other feature I should enable to get the behavior I'm looking for, let me know :).)
Bears-8$$MapSerializer._orderEntries() throws NPE when operating on ConcurrentHashMap$$It seems that the fix introduced for  #1411 in 2.8 can be problematic for ConcurrentSkipListMap (and possibly other map data structures).  doc for ConcurrentSkipListMap.doGet()
Bears-9$$AsPropertyTypeDeserializer ignores DeserializationFeature.ACCEPT_EMPTY_STRING_AS_NULL_OBJECT$$The  AsPropertyTypeDeserializer implementation does not respect the DeserializationFeature.ACCEPT_EMPTY_STRING_AS_NULL_OBJECT feature. When deserializing an empty String it throws DeserializationFeature.ACCEPT_EMPTY_STRING_AS_NULL_OBJECT instead of creating a null Object.
Bears-10$$DeserializationFeature.UNWRAP_SINGLE_VALUE_ARRAYS only works for POJOs, Maps$$Documentation of  DeserializationFeature.UNWRAP_SINGLE_VALUE_ARRAYS only mentiones exceptional behavior for more than one value in the array ("If more than one value is found in the array, a JsonMappingException is thrown."). But trying to parse { "value" : [] } with value as String produces the following Stacktrace: (Parsing as null might be expected instead)   This shouldn't be problematic when using  DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT , but it does not take precedence over DeserializationFeature.UNWRAP_SINGLE_VALUE_ARRAYS (bug?) and still gives me the error from above! Are there any workarounds? I still need to map single element arrays, that sometimes appear to be empty. (I am using version 2.5.1, tested also 2.6.0: same behavior)
Bears-11$$Enum key for Map ignores SerializationFeature.WRITE_ENUMS_USING_INDEX$$Version: latest 2.8  Failing unit tests added here:   https://github.com/SolaKun/jackson-databind/commit/6e095f75edd1de3eb33be5950c56d562bd6d584a Only java.util.Map test case provided, but doesn't work with EnumMap as well..
Bears-12$$Missing properties when deserializing using a builder class with a non-default constructor and a mutator annotated with  @JsonUnwrapped$$When deserializing using a builder class with a non-default constructor and any number of mutator methods annotated with @JsonUnwrapped, the  BuilderBasedDeserializer::deserializeUsingPropertyBasedWithUnwrapped method cuts short the process of adding SettableBeanProperties. The logic dictates that once all properties necessary to construct the builder have been found, the builder is constructed using all known SettableBeanProperties that have been found up to that point in the tokenizing process.  Therefore, in the case that the builder has a single property required for construction, and that property is found anywhere other than at the end of the JSON content, any properties subsequent to the constructor property are not evaluated and are left with their default values.  Given the following classes:   And given the following JSON string:   { We will see the following output:   However, if we place the  emp_id property at the end of the JSON string, we would get the following output:  If we were to place  emp_age and emp_first_name and emp_last_name all after the emp_id property in the JSON string, we would get the following output:
Bears-13$$@JsonProperty(access = READ_ONLY) together with generated constructor (lombok) causes JsonMappingException: Could not find creator property with name [...]$$The following class fails to deserialise with a  com.fasterxml.jackson.databind.JsonMappingException: Could not find creator property with name 's' (in class LombokObject) :  Whereas the following class - which is functionally identical but with constructors, getters and setters in the code - can be deserialised:   The exception is
Bears-14$$Jackson Deserializer security vulnerability via default typing (CVE-2017-7525)$$I have send email to  info@fasterxml.com
Bears-15$$@JsonIdentityReference not used when setup on class only$$I am trying to setup @JsonIdentityInfo/@JsonIdentityReference in order to serialize all references to a given class as Object Id (and deserialize them later using a custom ObjectIdResolver to retrieve the proper referenced instance)  I use @JsonIdentityReference(alwaysAsId=true) in order to enforce exporting the object id in all cases.  It does not work as expected when I define the annotation only on the class (but it works fine when I set it directly on the property). I would rather not have to define it on every property as I will probably miss some... From what I see in  BeanSerializerBase , the alwaysAsId is reset when not ObjectIdInfo is found on the accessor:   Shouldn't it be kept to the current value when no override is found ?  I tried to set it back in the default ObjectIdInfo created with NAME_FOR_OBJECT_REF but I am not sure if this is the right way to fix this. Here is test I added in  TestObjectIdSerialization for this case:
Bears-16$$Wrong serializer causing JsonMappingException$$I'm using spring-data-rest (3.0.0), which uses jackson-databind 2.9.0.pr2.  I'm not sure what have changed, since, not so long ago, I had an functional application. But now I'm getting:  "Could not write JSON document: java.lang.Double cannot be cast to java.lang.Integer (through reference chain: org.springframework.data.rest.webmvc.json.PersistentEntityJackson2Module$PersistentEntityResourceSerializer$1["content"]->**.Contrato["storageUtilizado"]); nested exception is com.fasterxml.jackson.databind.JsonMappingException: java.lang.Double cannot be cast to java.lang.Integer (through reference chain: org.springframework.data.rest.webmvc.json.PersistentEntityJackson2Module$PersistentEntityResourceSerializer$1["content"]->**.Contrato["storageUtilizado"])" I've been stucked with this problem for a while and I'm just assuming that there is something wrong when de Serializer for this specific field is defined   I need, at least, some directions...
Bears-17$$Extraneous type id mapping added for base type itself$$Looks like type id (name) matching base type is included in type resolution list, automatically. While this might be useful sometimes it seems quite odd, and probably should only be included if:    Base type is concrete and  Base type has explicit name (not add if default name used)
Bears-18$$Add support for handling primitive/discrepancy problem with type refinements$$(note: derived from  FasterXML/jackson-module-jaxb-annotations#64 ) The problem is that although  int and java.lang.Integer are related, logically, they are not related by inheritance (or implementation). Since some legacy code may try refinements in this axis it'd be nice to handle this somehow. Two basic approaches would be:   Just ignore primitive/wrapper override, return original type as is  Allow wrapper to "refine" primitive, return wrapper.  There is also related question of whether to allow "int to long" and similar refinements, but start with basics.
Bears-19$$JsonIgnoreProperties.allowSetters is not working in Jackson 2.8$$the version is 2.8.7.  the password cannot deserialize. the output is: {"username":"user"} null
Bears-20$$FromStringDeserializer ignores registered DeserializationProblemHandler for java.util.UUID$$Culprit appears to be  lines 155-161 of FromStringDeserializer :  The above lines appear to show that the exception will be thrown regardless of any problem handling logic.  Test Case:   The handler handles the issue properly; but an exception is thrown anyway:
Bears-21$$DateTimeSerializerBase ignores configured date format when creating contextual$$DateTimeSerializerBase#createContextual creates a new serializer with StdDateFormat.DATE_FORMAT_STR_ISO8601 format instead of re-using the actual format that may have been specified on the configuration. See the following code:  Using the  @JsonFormat annotation on a field will therefore reset the format to Jackson's default even if the annotation doesn't specify any custom format.  DateBasedDeserializer#createContextual behaves differently and tries to re-use the configured format:  Shouldn't the serializer follow the same approach ?
Bears-22$$Missing properties from base class when recursive types are involved.$$When a type hierarchy as follows is constructed and the base class' type is constructed first by the TypeFactory then serializing the sub class fails due to missing properties from the base class.   Serializes sub as  {"sub":2} where {"base":1,"sub":2} is expected. I've created a minimal scenario of this bug here:  https://github.com/slobo-showbie/jackson-recursive-type-bug I've experienced this bug in 2.7.8, 2.8.8, and 2.8.8.1
Bears-23$$StdDateFormat deserializes dates with no tz/offset as UTC instead of configured timezone$$Prior to version  2.8.9 , dates without time zone or time offset (eg 1970-01-01T00:00:00.000 ) were deserialised in the TimeZone set on the ObjectMapper. Starting from 2.8.9 , these dates are deserialised in UTC - which is a major (breaking) change in behaviour... Example:
Bears-24$$Infinite recursion when deserializing a class extending a Map, with a recursive value type.$$Hello, I am using jackson-databind 2.8.8, and have a class with an unusual definition (extending a Map, where the values are of the type of the same class). It seems like I am facing an infinite recursion issue.  To reproduce you can re-use or inspire from the class defined  here . Then, when executing the following code:    When calling  readValue() the mapper throws a StackOverflowException , here's the stacktrace:  Looking briefly into the code, it seems like because of the recursive definition of the class, the  equals call in MapLikeType may never get out of this loop. Any idea? Thanks.
Bears-25$$StackOverflowError in Dynamic StdKeySerializer$$There seem to be a problem (checked and doesn't seem to be fixed in latest version) with the serialize method of the Dynamic static class of the StdKeySerializer.   The problem comes from the fact that when  ser is null , the new ser returned by _findAndAddDynamic is incorrectly filled.  So say we are in  ser#1 , ser#1._dynamicSerializers now has the correct PropertySerializerMap$Single . However, result.serializer._dynamicSerializers has PropertySerializerMap$Empty . Therefore, a new call with that result ser#2 is made which ends up creating an infinite loop. Possible fix:    replace  If I'm mistaken please let me know, but It seems obvious when debugging that something's is not working as intended
Bears-27$$Changes to SourcePosition in 5.5.0 ?$$Hello,  according to #1081 I don't find any mentions of changes to the SourcePosition. In our use case we want to calculate the size of constructors and methods. Which worked just fine in 5.4.  Now with the 5.5 Snapshot I want to analyze a file which has a inner private class with no constructors. Spoon generates a default private constructor with one statement -> super() . The start line of this constructor is 1 and getPosition().getFile() returns null while the statements (super()) line is 383 and it has a file. My method throws a NP as my method size calculation now is wrong and gets passed the threshold and I try to access the file of the generated private constructor.  I always can implement the case to ignore generated constructors, but I just want to make sure this is intented or not.
Bears-28$$ParentNotInitializedException when processing comments with -c$$I am aware that comments can be processed using the command "-c"  since Spoon 5.2.0. Thanks for this feature.  When using Spoon to process comments in either code snippet below, ParentNotInitializedException will be thrown. An empty processor can be used to reproduce this issue. This happens in both Spoon 5.2 and 5.4.  public class Comment_1 {   }  public class Comment2 {   }  Details of the exception are as follows.  spoon.reflect.declaration.ParentNotInitializedException: parent not initialized for class spoon.support.reflect.code.CtCommentImpl (/home/jifeng/workspace/Temp4/src/main/java/example/Comment1.java:17)  at spoon.support.reflect.declaration.CtElementImpl.getParent(CtElementImpl.java:284) at spoon.support.compiler.jdt.JDTCommentBuilder.insertCommentInAST(JDTCommentBuilder.java:377) at spoon.support.compiler.jdt.JDTCommentBuilder.buildComment(JDTCommentBuilder.java:131) at spoon.support.compiler.jdt.JDTCommentBuilder.build(JDTCommentBuilder.java:96) at spoon.support.compiler.jdt.JDTBasedSpoonCompiler.buildSources(JDTBasedSpoonCompiler.java:387) at spoon.support.compiler.jdt.JDTBasedSpoonCompiler.build(JDTBasedSpoonCompiler.java:116) at spoon.support.compiler.jdt.JDTBasedSpoonCompiler.build(JDTBasedSpoonCompiler.java:99) at spoon.Launcher.buildModel(Launcher.java:712) at spoon.Launcher.run(Launcher.java:663) at spoon.Launcher.run(Launcher.java:106) at spoon.Launcher.main(Launcher.java:99)
Bears-31$$element.toString() crashes with a NP in DefaultJavaPrettyPrinter.visitCtTypeReference()$$When analyzing elasticsearch we get a NP when calling element.toString().  As this has something to do with type references, I can't give you a concrete source file with this problem, but rather a part of the project as tar archive. (  elasticsearch.tar.gz )
Bears-33$$CtTypeReferenceImpl#getSuperClass() fails in noClasspath mode$$The method has the following implementation:   As you can see, it doesn't check for noClasspath and, thus, may fail when calling  getActualClass() .
Bears-34$$ParentNotInitializedException on CtComments$$Hello,  When I build JavaFileTest from javapoet with comments enabled, the build throw me the following error:   snippet example:   assertThat(source)
Bears-35$$How could I disable static imports in the v55 output?$$I found v53+ are producing static imports.
Bears-44$$bug in removeStatement$$In this example, if you want to remove the second i++ with  block.removeStatement(block.getStatement(3)); , Spoon removes the first one.  (found by  @martinezmatias thanks!)
Bears-45$$CtFieldReference.getDefaultExpression() returns initializer from a field of another class$$Hi, I'm trying to collect and evaluate certain strings in the source repository.  I tried VisitorPartialEvaluator, but it runs into an infinite loop. The reason of this is that fields get mixed up. The code setup is like this:   Now if you try to read the return value of the  getKey() method, the CtFieldReference object will return the default value of ClassB.PREFIX , not BaseClass.PREFIX .
Bears-46$$CtElementImpl.getMetadataKeys() throws NPE$$I get NPE when invoking method getMetadataKeys() on CtElement. Looking through source code, it looks like metadata can be null. It should have null check and return null like getMetadata() method or return empty set.
Bears-48$$[generic type] Regression in being able to spoon Guava$$It seems that  #1218 introduced a regression on Guava project which is used by our CI to check the behaviour of Spoon, see the trace :     See full stack trace:   https://ci.inria.fr/sos/job/Guava/262/console
Bears-54$$Exception at compilation due to a constructor with private visibility$$Hello,  I'm having an issue while instrumenting the source code of  AssertJ with Spoon. The instrumentation part will work, but the compilation part will fail due to the following error:  I created a small Maven project with the part of the AssertJ source code that I cannot instrument/compile with Spoon.  The project architecture is the following:   According to the Exception message, the problems comes from the class  BooleanArraysBaseTest , which contains the following code:  The statement  arrays = new BooleanArrays(); refers to the BooleanArrays class contained in the same package ('internal'), which is a Singleton, having a constructor with the package visibility:  The other class also called  BooleanArrays , but contained in the other package ('test') has a private constructor. My Launcher configuration is the following:   Is there something wrong with my configuration ? I managed to instrument several other projects, but not this one.  Tell me if you need any other information. An archive containing this project is available  here . Thank you,  Thibault
Bears-55$$Variable called "java" messes with the imports$$Hello,  I'm Spooning the JUnit4 source code, and in the following class , a variable has been named "java":  String java = System.getProperty("java.home") + File.separator + "bin" + File.separator + "java"; I configured my launcher with  launcher.getEnvironment().setAutoImports(false); , after running the launcher, the following code is generated:  java.lang.String java = ((((java.lang.System.getProperty("java.home")) + (java.io.File.separator)) + "bin") + (java.io.File.separator)) + "java"; Which is completely normal, but the compilation will fail because "java.lang.System" refers to the "java" String declared earlier, which has no "lang" attribute (obviously).  Since my previous issue I'm running Spoon using  launcher.getEnvironment().setAutoImports(false); . Since it is quite specific, I'm renaming the Java variable in the source code, but it can be a bit time-consuming, when there's multiple classes with a similar variable.  Thibault
Bears-71$$issue with isOverriding behavior when extending TypeParameters$$If you consider the interface  Iterable<E> which contain a method forEach(Consumer<? super E>) and if you create a class with a T extends String which implements Iterable<T> , then you implement your own version of forEach : if you use ClassTypingContext.isSameSignature() on the two forEach methods, it will return false because they do not have the same type parameter. I'm really not sure if this is a bug or not: in the overriding method, the type parameter is more defined, so the signature is not exactly the same. But then, if we only use  isSameSignature in getAllMethods (see #1375 ) we will get both Iterable#forEach and ArrayList#forEach , when using it on ArrayList . WDYT? Should we consider the signature are the same, or should we consider that  getAllMethods should indeed return the two different methods? Edit: Actually I extended my test to check with  isOverriding and it returns false which is obviously wrong. So there's a real issue here.
Bears-78$$NPE on DefaultJavaPrettyPrinter#printCtFieldAccess$$More intel about bug reproduction can be found on the following issue:  HabchiSarra/SmellDetector#8 The full stack trace using spoon 5.9.0-SNAPSHOT below
Bears-79$$Processor is not using templated type when process method is in an abstract class$$We define an abstract spoon Processor declaring a process method on a templated type:     And create a concrete class extending the previous one:      The problem is that both the concrete processors are receiving every classes that matches the  upper bound of our template.
Bears-84$$Persist fails on entity without id and version field if @EnableAuditing [DATACMNS-957]$$opened and commented Follow domain should be persist:   It works, as long as auditing is turned off. After putting  @EnableAuditing to application follows exception is thrown:   Description: If auditing is enabled those steps are executed:    Determine strategy to fill auditing fields  Find fields that should be filled via auditing  Fill found fields  If strategy can't be determined (because id and version is not available in domain) exception is thrown and object isn't persisted.  This exception is also thrown if you don't have any fields in model that are filled via auditing.  There is no need to throw this exception if no fields are filled via auditing. Some code to make it clear:     I've patch for this ticket.  PR: #189   Issue Links:     Referenced from: pull request #189  Backported to:  1.13 GA (Ingalls) , 1.12.7 (Hopper SR7) , 1.11.7 (Gosling SR7)
Bears-85$$NullPointerException in ProjectingJackson2HttpMessageConverter [DATACMNS-972]$$opened and commented Managed to get a nullpointer after switching to spring-boot 1.5.0.RC1 from 1.4.3.RELEASE  Nullpointer happens because the "rawType" is null when the "type" is generic type(like T or D).   With generic type the "targetClass" is initialised here correctly using ResolvableType.forMethodParameter(parameter).resolve():   spring The new "ProjectingJackson2HttpMessageConverter" converter is initialized as first converter here because spring-boot defines json-path depenency.   spring Stacktrace:     Affects: 1.13 RC1 (Ingalls)  Reference URL:  https://jira.spring.io/browse/DATACMNS-885  Attachments:      Backported to:  1.13 GA (Ingalls)
Bears-86$$ProxyingHandlerMethodArgumentResolver handles interfaces not intended for projection [DATACMNS-776]$$opened and commented A Spring Boot application that depends on  spring-boot-starter-data-pa and uses Spring Mobile will create a proxy for Spring Mobile's Device interface when it's injected into a handler method. Calling isMobile on this proxy fails as follows:  The culprit is  ProxyingHandlerMethodArgumentResolver which takes responsibility for any argument that's an interface. I can work around the problem by ensuring that Spring Mobile's DeviceHandlerMethodArgumentResolver appears before ProxyingHandlerMethodArgumentResolver in Spring MVC's list of argument resolvers but I'd prefer not to have to do so. Can ProxyingHandlerMethodArgumentResolver be fixed so that it either doesn't claim responsibility for anything that's an interface, or so that it returns a working proxy?   Affects: 1.10.2 (Fowler SR2), 1.11 GA (Gosling)  Issue Links:     Backported to:  1.13 GA (Ingalls) , 1.12.7 (Hopper SR7) , 1.11.7 (Gosling SR7) 4 votes, 8 watchers
Bears-87$$Converting to Vavr Option fails for present value [DATACMNS-1087]$$opened and commented Curently  QueryExecutionConverters tries to invoke Vavr's Optional.of like an instance method rather than static one. This causes exception:    Affects: 1.13.4 (Ingalls SR4)  Referenced from: commits ,
Bears-88$$RepositoryBeanNameGenerator fails to resolve bean names for custom implementations detected via Spring's component index [DATACMNS-1115]$$opened and commented After upgrading to Spring Boot 2.0.0.M2 and Spring Data Kay.M4 I cannot start my microservices any more which are accessing MongoDB. A testcase is appended to produce the stacktrace below.  First I thought it is a Spring Boot issue spring-projects/spring-boot#9780 Stacktrace:    Affects: 2.0 M4 (Kay)  Attachments:     Backported to:  1.13.5 (Ingalls SR5) , 1.12.12 (Hopper SR12)
Bears-89$$Invalid generics resolution for locally declared wildcard and fully resolved target type [DATACMNS-1138]$$opened and commented Given the following context:    An entity declares a field which type is a class with a wildcard type  An implementation of the field's class is typed with a custom object  A custom converter has been declared for the custom object  We persist an entity with the custom class in Mongo  Then when we retrieve the entity from the database, the field with the custom type is not deserialized by the custom converter.  This problem does not happen if:   We remove the wildcard from the declared field  We use a type that does not require a custom converter (e.g. Integer)  I'm not sure if this description is clear, please take a look at the project on GitHub:  https://github.com/mclem/spring-data-mongodb-generics to reproduce the problem by running mvn test   Affects: 1.12.11 (Hopper SR11), 1.13.6 (Ingalls SR6), 2.0 RC2 (Kay)  Reference URL:  https://github.com/mclem/spring-data-mongodb-generics  Issue Links:     Backported to:  1.13.7 (Ingalls SR7) , 1.12.12 (Hopper SR12)
Bears-90$$AbstractPersistentProperty.getRawType() does not consider generics [DATACMNS-1139]$$opened and commented  AbstractPersistentProperty.getRawType() currently uses the field's or property descriptor's type which in turn doesn't use our generics resolution mechanism which means for generic fields you'll get different results if you call ….getTypeInformation().getType() and ….getRawType()   Affects: 1.12.11 (Hopper SR11), 1.13.6 (Ingalls SR6), 2.0 RC2 (Kay)  Backported to:  1.13.7 (Ingalls SR7) , 1.12.12 (Hopper SR12)
Bears-91$$Jackson configuration is not used by ProjectingJackson2HttpMessageConverter  [DATACMNS-1152]$$opened and commented  ProjectingJackson2HttpMessageConverter is not using the default MappingJackson2HttpMessageConverter constructor to instantiate an ObjectMapper (that uses Jackson2ObjectMapperBuilder to create a Jackson ObjectMapper based on application configuration), instead ObjectMapper is created directly in SpringDataWebConfiguration.extendMessageConverters(…) . That causes  ProjectingJackson2HttpMessageConverter to not use Jackson configuration from application.properties to create the ObjectMapper and there is no possibility to configure Jackson ObjectMapper . That also breaks MappingJackson2HttpMessageConverter configuration functionality. To solve that issue ObjectMapper creation should be delegated to MappingJackson2HttpMessageConverter default constructor   Affects: 1.13.6 (Ingalls SR6), 2.0 RC2 (Kay)  Backported to:  1.13.7 (Ingalls SR7)
Bears-92$$AnnotationRevisionMetadata throws ClassCastException [DATACMNS-1173]$$opened and commented  AnnotationRevisionMetadata throws ClassCastException at line 90 :  Most likely leftovers during migration to  java.util.Optional   Affects: 2.0 RC3 (Kay)
Bears-93$$EntityInstantiators deallocate params required for instantiation of parent object [DATACMNS-1175]$$opened and commented Fetching nested document from MongoDB into Kotlin data class structure will sometimes result in NullPointerException. This is caused by  DefaultingKotlinClassInstantiatorAdapter.createInstance(..) calling ClassGeneratingEntityInstantiator.deallocateArguments(..) method cleaning up the shared params array. Doing this while instantiating a child object will clean up all previously prepared arguments for parents constructor and thus causing NPEs on non-null parameters. Note that everything was fine while using version of Spring Data bundled with Spring Boot 2.0.0.M3    Affects: 2.0 RC3 (Kay)  Referenced from: pull request #247 , and commits , ,
Bears-94$$Failing generic type resolution of generic types within nested generic fields [DATACMNS-1196]$$opened and commented It seems that the type resolution is not working properly when having nested object composition with generic type.  Example of model: constructors, getters,... ommited  And create instance of  Outer with  When we create an instance of  Outer which has reference to instance of Generic whose generic type is MyEnum then if we save Outer instance using MongoTemplate it's persisted in db correctly converted to mongo's document.  { But, when we try to read it from db it is mapped incorrectly back to  Outer . Field myList in instance of Inner contains a List which contains instances of String , but field elem in instance of Inner is mapped correctly and it really contains an instance of MyEnum . Seems that problem is in MongoConverter . I'm attaching a simple project which is able to reproduce problem described above. In tests, I'm not actually storing an instance to mongo collection, but rather using only MongoConverter to convert an instance to Document and than back to Outer . I don't know if workaround for this cold be writing a custom Converter . My workaround for this (in real project) was to manually convert a Document to some domain specific instance, but that is really annoying.  I know that mapping from mongo types back can be tricky and sometimes type information is lost, but that is not case here. For comparison, I've tried Jackson 's ObjectMapper to do serialization of instance of Outer to JSON string and than de-serialize JSON on back to Outer and it seems that Jackson resolves  generic types correctly.   Affects: 1.13.8 (Ingalls SR8), 2.0 GA (Kay)  Attachments:     Backported to:  2.0.1 (Kay SR1) , 1.13.9 (Ingalls SR9)
Bears-95$$ClassGeneratingPropertyAccessorFactory.isTypeInjectable(…) fails with NPE for entities in default packages [DATACMNS-1201]$$opened and commented Introspecting ClassGeneratingPropertyAccessorFactory support for an entity fails with an NPE if the entity resides in the default package.     Affects: 1.13.8 (Ingalls SR8), 2.0 GA (Kay)  Referenced from: pull request #256  Backported to:  2.0.1 (Kay SR1) , 1.13.9 (Ingalls SR9)
Bears-96$$Repositories does not expose registered repository for proxy type [DATACMNS-1215]$$opened and commented Converting an entity to an ID using  DomainClassConverter.ToIdConverter fails if the entity instance is actually a proxy. This is because DomainClassConverter.ToIdConverter.matches(…) only checks for a repository with the sourceType.getType() . In the case of a Hibernate proxy, this type is EntityClass_jvst_###_## but the repository is registered with the key EntityClass . For my application, the inability to convert a proxy causes an exception in Thymeleaf template generation, which prevents the page from loading completely.  It may not be possible to know when the persistence provider will return a proxy or a raw entity.  For example, the  JpaRepository.getOne(…) method may return a proxy or may cause subsequent queries to return proxies. It would be helpful if DomainClassConverter attempted at least one additional match by going one step up in the class hierarchy (sort of like GenericConversionService.Converters.find(…) does it) because the entity class is the superclass of the proxy and this would prevent the failure   Affects: 1.13.8 (Ingalls SR8)  Reference URL:  https://stackoverflow.com/q/47318903/3179666  Backported to:  2.0.2 (Kay SR2) , 1.13.9 (Ingalls SR9)
Bears-97$$When true setOneIndexedParameters still behaves as false in the links of the json response [DATACMNS-563]$$opened and commented When setting this to true, the argument 1 accepted from the HTTP request is indeed considered to be the index of the first page, but the json response still displays links as if the first page is indexed 0. For example, requesting the page 3 gets the page 3 but the links are described ignoring the index start at 1. The prev link should show 2 and the next link should show 4. As it stands now, the next page link has the same index as the current page in the request.     Affects: 1.8.2 (Dijkstra SR2)  Referenced from: pull request #267  Backported to:  2.0.3 (Kay SR3) , 1.13.10 (Ingalls SR10)
Bears-99$$Blank map and no pointer when tracker is sending vibration alarm$$Hello,  Im very happy with the traccar platform but got a strange issue.  I got about 40 trackers connected but 2 is missing map and pointers. I noticed those 2 trackers is marked with ´vibration´ alarm and ignition OFF. Is it a bug or am I doing something wrong ? trackers is running on h02 protocol.  Thanks
Bears-103$$ClassCastExecption$$Hi,  I have started using a meitrack tc68s device, however when I try and generate a summary/trip report it returns the following error in console:  The device is not in the future and has the correct timezone, also I am using the official build. Any recommendation?  All the other, osram works fine.
Bears-108$$cGuard protocol decoding issue$$I've got a pair of cGuard Atom devices,  one of the them is '2015' and another one - '2016'. I'm trying to install and configure the Traccar server (inside Docker) to acquire data from the devices.  Traccar version: 3.10,  cGuard Atom fw: 3.2.3 (the latest available) The server successfully detects a new device (2017-04-09 03:06:43  WARN: Unknown device - 35338606530**** (***)) and after a couple of minutes begins to decode gps-data. However, the navi data seem to be being decoded incorrectly. All the testing time, coordinates are zeroes, the datetime mark correspond to Unix epoch time, etc.. (see below).   The hex-decoder on the Trackar site correctly decodes HEX-parts of the data:
Bears-116$$MU-201 v3.xx doesnt work?$$Hi,  i've tried to install my tracker in Traccar but it doesn't work. The Logfile was generated and everything is running but not the tracker...  HEX is translatet to:   Port 5051  How can i add the device?  Kind regards  Daniel
Bears-131$$meitrack temp sensor with negative value$$Hi Anton,  I'm receiving a wrong value from temp sensor for negative temp values, example: data for temp is 06FB2E which should translate to -12.34°C according to doc for protocol v3.  Could you please check if traccar is reading temp correctly for negative values?  a sample data to test with:   Regards,
Bears-149$$When i use the parameters configured in the dubbo provider in the routing rules, the rules can not be matched$$如果将参数添加到dubbo provider中，例如：   <dubbo:provider  serialization="fastjson" /> 这样生成的url中会带有 default.serialization=fastjson 这样的参数。 如果路由规则设置为 "=> serialization=fastjson"，是无法过滤出带有 default.serialization=fastjson 的提供者的。
Bears-150$$Locale deserialize 'zh-hant_CN'$$zh-hant_CN will convert to zh_HANT_cn Locale include (language, country, variant), Locale.toString() use '_' to split then  {language}_{country}_({variant}_# | #){script}-{extensions} but Jackson deserialize Locale use '-' or '_'  : (  code: LocaleHandle.readResolve()  iana language-tags   rfc4647 language lookup    in jdk1.5 -> 1.8
Bears-156$$Hibernate Subselect Entity not supported by EntityMetamodelImpl$$Description  After playing a bit with table functions (see also  #181 ), I had the idea to experiment with mapping a generate_series query to an entity using the annotation. Find below the produced stack trace. A trivial work around is to wrap the query into to a view and map that instead. I am uncertain whether a fix for this is worthwhile, but it could perhaps be a step towards implementing table functions (  #181 ).   Expected behavior  Actual behavior  Steps to reproduce  Environment  Version:            1.2.0.Alpha3  JPA-Provider:       Hibernate 5.2.12 DBMS:               PostgresSQL Application Server: Wildfly
Bears-166$$rest api returns wrong address status {"isReady":true,"phase":"Pending"}$$address-space: standard  addresses: queue(sharded-queue)/topic(sharded-topic)  addresses deployed into address-space are ready to use (simple send/receive) but .status.phase is set to "Pending" reproducer    create     deploy     get all addresses     result:   address_space definition: standardSpace.json   addresses definition: standard_qt.json   however in standard-controller log you can see that addresses are in phase "Active:   ConfigMap of myqueue contains phase "Active" as well   I'll try to reproduce with brokered...
Bears-167$$address-controller allows to create multiple addresses with the same "spec.address" value$$reproducible via following steps:    create standard address space (reproducible with brokered as well)  deploy 3 addresses into this address space     all addresses were created successfully, console shows only one of those addresses, next address appears once previous one is removed.  And only first of multiple addresses has isReady attribute set to true in configMap  standard_anycast.json
Bears-168$$address-controller: NPE when required parameters (address, plan or type) are not set$$Description:  When required parameter (address,plan or type) in address definition is not set then it cause NPE in address-controller.  https://github.com/EnMasseProject/enmasse/blob/master/address-model-lib/src/main/java/io/enmasse/address/model/v1/AddressV1Deserializer.java#L36 Steps to reproduce:    create brokered address-space "brokered-space"  create address without required parameter: "brokered_incorrect_address.json"    Automated test:  we have no automated test for that yet output from address-controller log:
Bears-170$$A mapping service mapping error has its toString value inserted into an integrated dataset$$How to Reproduce     Go to the mapping service  Create a new mapping project with  Add TypeTestRef as new source  Edit label attribute  Fill in  Create integrated dataset  Expected behaviour  Mapping fails because the validation for the label to label mapping contains script errors  Observed behaviour  The mapping is executed and the toString() value of the error is inserted as a label
Bears-171$$When I upload data with one row, data is not uploaded$$How to Reproduce  Upload with advanced importer, add mode:   eric_de_test_model.xlsx Upload csv in this zip:  eu_bbmri_eric_DE_biobanks.csv.zip Expected behavior  1 row is added to the biobanks table  Observed behavior  Import succeeds, 0 rows imported
Bears-172$$Repository.findOne method fails to return row for row level secured entity type if first row isn't readable$$Code inspection  FindOne shouldn't check if first row of delegate is readable but find first readable row.
Bears-173$$Importing an entitytype with several columns with the same name, import without errors$$How to Reproduce  Import a datasheet with multiple columns that have the same name.  Expected behavior  An error telling me to only use the name of every attribute once per entitytype  Observed behavior  Everything imports fine and I have issues much later then one would expect.
Bears-174$$One-to-many with integer ids retrieval broken$$How to Reproduce  Upload:   string-id.xlsx Go to dataexplorer, select Subjects table  I don't like the order of the samples, so I want to change the ID attribute datatype of the samples to int Upload:  int-id.xlsx Go to your table again Expected behavior  My beautiful table, nicely int sorted --> happy datamanager  Observed behavior    --> Sad datamanager
Bears-175$$NPE importing EMX with abtract entity type data$$How to Reproduce  Import  this file Expected behavior  Success, or if I am not allowed to add data to abstract entities I expect a message  Observed behavior  Importer hangs, server logs report a null pointer exception in the  dataservice.add() method.
Bears-180$$NPE for google cloud storage$$Hi ,  Any time I try to access Resource from the google storage it throws the following NPE. It happens on both read and write . Here is how the pom looks like   Here is the code   I even tried checking out the entire repo and just run the code as it is  from spring-cloud-gcp-storage-resource-sample and class WebController by changing my bucket name and still get the same NPE  I removed the entire .m2 directory and started all over all and still the issue persists  I double checked I have access to my bucket and even tried the same form my service account that have project admin access , but the problem persists
Bears-184$$Improve identifier metadata detection for XML based entity mappings [DATAJPA-658]$$opened and commented I have a model in POJO's and my persistence configuration in a separated project with an orm.xml file. I want to expose my persistence API and I have detected that entities are only configured when they are annotated with persistence annotations (  @Id for example). We cannot annotate our entities as they come from a target model which we don't have the source code. It would be great that Spring Data REST were configurable using  orm.xml files or other .xml source apart from annotations. Thank you    Affects: 1.7.1 (Evans SR1), 1.8 M1 (Fowler)  Issue Links:     Referenced from: pull request #146  Backported to:  2.0.4 (Kay SR4) , 1.11.11 (Ingalls SR11) 2 votes, 6 watchers
Bears-185$$NativeQuery with Pagination validation error at startup [DATAJPA-928]$$opened and commented According to Example 50 at  Using @Query docs , it's possible to use a native query with pagination using Pageable but in my case it's failing with a org.springframework.data.jpa.repository.query.InvalidJpaQueryMethodException. NativeJpaQuery constructor is checking if the query has a Pageable parameter and if the queryString contains a #pageable or #sort sequence. The query has Pageable parameter but it  does not contain a #pageable string:   If I provide a #pageable string at the end of the query, validation passes, but when the query executes, it fails saying that it's expecting 3 parameters instead of 2.  Funny thing is that, when the server is starting, if I set a breakpoint inside NativeJpaQuery and change containsPageableOrSortInQueryExpression from false to true manually, validation passes just fine and the query executes well, paginating    Affects: 1.10.1 (Hopper SR1), 1.10.2 (Hopper SR2)  Reference URL:  http://stackoverflow.com/questions/38349930/spring-data-and-native-query-with-pagination  Issue Links:     Referenced from: pull request #246 , and commits , , ,  Backported to:  2.0.4 (Kay SR4) 1 votes, 12 watchers
Bears-199$$Stop receiving records with error  "Last request was dispatched at...but no response as of ...Cancelling subscription, and restarting." (KCL 2.0)$$I have a Kinesis stream of 2 shards with data published to it continuously. I use KCL 2.0.1 java to connect to the stream with polling (by populating retrievalConfig.retrievalSpecificConfig with a PollingConfig object). It works completely fine and keeps receiving messages from both shards for the first 10 minutes. After that, it stops receiving any message, even there is data continuously published to the stream. I leave the process running for 5 more minutes and issue persists. After that I restart the process, and it starts receiving messages again from both shards, but stops receiving messages again after running for 10 minutes. Issue happens repeatedly.  No throttling error is seen in logs. Instead, following errors are seen in logs:   2018-10-19 14:12:43,531 ERROR [main] shardId-000000000000: Last request was dispatched at 2018-10-19T03:12:07.772Z, but no response as of 2018-10-19T03:12:43.531Z (PT35.759S).  Cancelling subscription, and restarting. This kind of logs appear once for every 35 seconds for each shard. When it first appeared, it happened to shardId-000000000000, and no more messages are received from this shard. Then it appeared for shardId-000000000001 as well, and no more message is received from this shard.  To isolate the publishing factor, I've done another test where I first published lots of data to the stream without consuming. Then I stop publishing and start the consumer application. Same behaviours are observed.  Same behaviours are observed with KCL 2.0.3.  I've extracted and attached the relevant application logs and error logs for reference.   app.log  error.log Any idea?
Bears-202$$Calling  blacklistLibOrExtJars without arguments causes an Exception$$Calling  blacklistLibOrExtJars() without arguments throws java.lang.IllegalArgumentException: Can only blacklist jars by leafname: /System/Library/Java/Extensions/MRJToolkit.jar while whitelistLibOrExtJars() without arguments works fine.
Bears-206$$Large HTML File conversion to PDF hangs.$$Hi,  I am trying to convert large HTML File approximately 600 pages which is not passing the conversion and hangs.  Following is my observation after debugging the core.  PdfRendererBuilder.class file has following method call.   renderer.layout(); // This action takes significant time but completes the process.  when I looked into it renderer.createPDF()  is trying to create entire PDF in memory (document) and after completion it starts writing to OutputStream.  Can we write it directly to OutputStream page by page? I think this might solve the problem.  Following is my code snippet please check the same if I am doing anything wrong here.   In  above code snippet it is not completing  builder.run(); process and hangs. Please help me with the solution.  Thanks in advance.
Bears-211$$Unable to set a compression input/output decorator to a  SmileFactory$$I have a special need for the  riak-java-client which only allows me to use an ObjectMapper to serialize/deserialize key-values, I would like to decorate a SmileFactory with compressors like LZ4, Snappy or GZip but at the moment this is not possible, when I try a mapper like the following:   This is the exception I get:  I used Gzip as an example, in reality I'm using both LZ4 and Gzip and both throw exceptions when I try with a  SmileFactory , this works perfectly with a JsonFactory , the reason for me to prefer a SmileFactory over a JsonFactory is because it is notice-able faster than the JsonFactory so basically it'll help compensate the price I pay for compression.
Bears-212$$YamlGenerator closes the target stream when configured not to$$Bug description  YamlGenerator closes the target stream when configured not to.  Versions used  jackson-dataformat-yaml 2.9.2  jackson-databind 2.9.6 Expected result  The target stream not closed when writing a value. No output when running reproduction script/program.  Actual result  The target stream is closed when using the YamlGenerator, with the following output when running the reproduction script/program.   Steps to reproduce
Bears-219$$feat: add support for ${java.version} in pom.xml$$Hi !  I have an issue creating a MavenLauncher for projects that have ${java.version} in their POM.xml .  Replacing it with  1.8 for example seems to work around. Thank you for your help !
Bears-225$$ReactiveCommandSegmentCommandFactory resolves StreamingOutput for all reactive types$$I'm using Redis Lettuce dynamic client as described in official documentation  https://github.com/lettuce-io/lettuce-core/wiki/Redis-Command-Interfaces#command-interfaces.response-types My commands interface looks exactly the same   The problem is when method get cannot find value by key there's exception thrown instead of returning empty Mono.   When using predefined RedisReactiveCommands get works fine, it returns empty Mono. So it seems like a bug to me.  The Redis Lettuce version being used is   < Also checked with 5.0.4 RELEASE - issue remained
Bears-230$$TracingP6SpyListener is not computing the Tags.DB_TYPE properly.$$Type: bugfix  In the TracingP6SpyListener class, line 112   We should take into account that a url returned by a DatabaseMetaData can be null.
Bears-240$$Context must read system properties to rewrite properties from file.$$Context must read system properties to rewrite properties from file.
Bears-241$$should use provided pullRequestTitle when creating the PR$$Summary  Related to  societe-generale/ci-droid#6 : new "pullRequestTitle" field needs to be taken into account when creating the PR Type of Issue  It is a :       Motivation  Current Behavior  the PR is created, but takes the commitMessage as title : now that a dedicated field (pullRequestTitle) has been introduced in the model, we should use it  Expected Behavior  use pullRequestTitle if provided - otherwise use the branch name as PR title  Steps to Reproduce (for bugs)  Your Environment    Version used: 1.0.5  OS and version:  Version of libs used:
Bears-244$$ClassGeneratingPropertyAccessorFactory needs custom ClassLoader for defineClass() [DATACMNS-1422]$$opened and commented The  ClassGeneratingPropertyAccessorFactory fails to generate classes in an OSGi environment, where the ClassLoader for the model project, the store implementation and Spring Data is different. Here is the error we are facing:  The problem seems to be that  PropertyAccessorClassGenerator.generateBytecode() adds the interface PersistentPropertyAccessor which lives in Spring Data. In generateCustomAccessorClass() the ClassLoader of the model entity is used. Therefore the ClassLoader of the custom model project needs access to all classes which are added by the factory (especially the package org.springframework.data.mapping ). To resolve this problem, a child ClassLoader of the entity should be used that is able to access both projects: Spring Data and the custom entity model. Else this has to fail because different classes are mixed which cannot be accessed by a single ClassLoader    Affects: 2.1.2 (Lovelace SR2)  Attachments:      Referenced from: pull request #324  Backported to:  2.1.3 (Lovelace SR3)
